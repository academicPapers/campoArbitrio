---
title: "Crítica ao Campo de Arbítrio do Avaliador"
subtitle:  "Como fazer uso do intervalo de predição corretamente"
author: 
  - Luiz F. P. Droubi^[SPU/SC, lfpdroubi@gmail.com]
  - Carlos Augusto Zilli^[IFSC, carlos.zilli@ifsc.edu.br]
  - Willian Zonato^[SPU/SC, will.zonato@gmail.com]
  - Norberto Hoccheim^[UFSC, hochheim@gmail.com]
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
output:
  pdf_document:
    includes:
      in_header: preamble.tex
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: no
  word_document: default
  html_document:
    fig_caption: yes
    keep_md: yes
classoption: a4paper, 11pt
documentclass: article
geometry: left=2.5cm,right=2.5cm,top=3cm,bottom=2.5cm
link-citations: yes
linkcolor: red
urlcolor: magenta
citecolor: green
csl: ABNT_UFPR_2011-Mendeley.csl
bibliography: skeleton.bib
always_allow_html: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.path = "images/", out.width = "65%",
                      dev = "CairoPNG", dpi = 600, fig.align = "center",
                      fig.pos = "H", warning = FALSE, message = FALSE)
type <- knitr::opts_knit$get("rmarkdown.pandoc.to")
library(appraiseR)
library(car)
library(knitr)
library(kableExtra)
library(xtable)
library(sjPlot)
library(plotly)
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot(12))
library(dplyr)
library(lmtest)
#library(robustbase)
library(sandwich)
library(car)
seed <- 1000
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}
red = gg_color_hue(1)
epsilonsd <- 200
```

# Resumo {-}

Neste trabalho são apresentados aspectos teóricos e práticos relacionados ao
conceito de Campo de Arbítrio (CA) do Avaliador, dado a imnportância deste
conceito na Engenharia de Avaliações. Foram elencados os critérios previstos na
normativa que possibilitam ao avaliador fazer uso do Campo de Arbítrio,
detalhando cada um destes critérios levantados e ponderando se a adoção do
conceito de Campo de Arbítrio do avaliador é uma condição suficiente e
necessária para a solução dos problemas práticos enfrentados pelo avaliador.
Para melhor ilustrar, foram elaborados estudos de diversos casos com a geração
de dados randômicos simulando o problema da micronumerosidade de dados de uma
mesma característica, comparando os resultados obtidos com a adoção de diversas
abordagens, fazendo uso tanto do Campo de Arbítrio do Avaliador  quando do
intervalo de predição (IP) das previsões efetuadas com os modelos obtidos em
cada abordagem. Outro aspecto importante abordado lateralmente neste trabalho é
sobre a previsão de valores de venda a partir de dados de oferta, haja vista que
a falta de dados de oferta e, em consequência a falta de um fator oferta obtido
cientificamamente, é um dos grandes motivos que levam os avaliadores a fazerem
uso do Campo de Arbítrio. Ao final, a partir da pesquisa elaborada e dos
resultados obtidos são feitas recomendações visando uma melhoria na NBR 14.653
numa eventual revisão desta.

# Introdução

Recentemente, durante o [XX Cobreap](http://www.cobreap.com.br/2019/), foi
apresentado o artigo intitulado "Crítica à Avaliação Intervalar na NBR14.653-02"
[@droubi2019]. Neste trabalho recomendou-se que, eventualmente, em uma próxima
revisão da parte 2 da NBR 14.653-02 [-@NBR1465302], a avaliação intervalar, tal
como está normatizada no momento, não seja mantida como se encontra. Com base
nos resultados obtidos naquele artigo, foram elaborados outros estudos, com
ajustes diferentes, com o intuito de verificar a pertinência das conclusões
obtidas na, assim como acrescentar alguns pontos no que tange ao Campo de
Arbítrio do avaliador, especialmente no que tange à omissão de variável
relevante. Também foram feitas considerações a respeito do fator oferta.
Pretende-se com este trabalho deixar detalhes de uma proposta de como
poder-se-ia modificar o atual consenso da avaliação intervalar numa futura
revisão normativa.

# Desenvolvimento e Fundamentação

Nesta seção serão abordados o conceito básico de campo de arbítrio, como
definido pela @NBR1465302, refletindo sobre as situações em que ele é aplicável 
e quais seriam as alternativas básicas ao seu uso.

## Campo de Arbítrio do Avaliador

A NBR 14.653-02 [@NBR1465302] define que:

> "_o Campo de Arbítrio pode ser utilizado quando **variáveis relevantes** para
a avaliação do imóvel **não tiverem sido contempladas no modelo**, por escassez
de dados de mercado, por inexistência de fatores de homogeinização aplicáveis ou
porque essas variáveis não se apresentaram estatisticamente significantes em
modelos de regressão, **desde que a amplitude de até mais ou menos 15% seja
suficiente para absorver as influências não consideradas e que os ajustes sejam
justificados**_".

Um ponto levantado por @droubi2019 é que a comparação dos valores arbitrados
dentro do CA não deveriam ser comparados ao intervalo de confiança da regressão
linear, pois *o intervalo de confiança é para a média*, ou seja, o intervalo de
confiança é apenas para aferir a precisão do cálculo dos valores ajustados pela
reta de regressão (média + variância explicada) e não serve para contemplar
outros efeitos não calculados pelo modelo para a avaliação do bem-avaliando.
Para isto, a comparação devida seria com o intervalo de predição, ou seja, o
intervalo onde se encontram os valores reais observados do mercado e não apenas
os valores médios (a soma da média e da variância explicada e não-explicada).

Este primeiro aspecto refere-se mais à questão da avaliação intervalar do que ao
campo de arbítrio em si, e poderia ser contornado simplesmente com a mudança dos
critérios da avaliação intervalar, adotando-se critérios mais adequados para a 
elaboração de intervalos.

Um outro ponto igualmente importante levanto por @droubi2019, porém, diz
respeito apenas ao CA: o intervalo fixo, de $\pm$ 15%, pode até ser razoável em
algumas situações, mas pode levar a valores de baixíssima probabilidade de
ocorrência prática em mercados de baixa variabilidade, ou ainda, pelo contrário,
num mercado de grande variância, levar a valores que sequer chegam próximos dos
valores extremos observados no mercado.

Porém, entende-se que @droubi2019 não esclareram completamente os motivos pelos
quais um mercado pode vir a apresentar um modelo com um intervalo de predição
tão grande, enquanto noutros o intervalo de predição pode ser mais estreito.

Como será visto a seguir, isto pode ser uma questão do próprio mercado, mas 
também pode estar relacionado às variáveis importantes não contempladas no 
modelo. Na próxima subseção será analisado um dos fatores que podem levar à
omissão de variáveis importantes num modelo de avaliação de imóveis.

## Escassez de dados de mercado - Micronumerosidade

Um dos fatores que levam à omissão de variáveis relevantes do modelo, o que 
embasa a utilização do CA do avaliador, é o critério da micronumerosidade.

De acordo com o Anexo A da referida norma, quando da utilização de variáveis
dicotômicas ou qualitativas, um número mínimo de dados de cada característica,
variando de 3 a 10, a depender do tamanho da amostra, devem ser efetivamente
utilizados. Em geral, o número de dados de cada característica ($n_i$) deve ser
igual a 10% do número total de dados ($n_i > 10\% \ n$) da amostra, limitado a
um mínimo de 3 dados caso a amostra possua um número total de dados menor do que
30 ($n<30$) e um limitante superior de 10 dados $n_i > 10$ caso a amostra possua
um número de dados maior do que 100 ($n > 100$).

A NBR 14.653-02 não é clara, no entanto, sobre como proceder no caso de o
avaliador encontrar em sua amostra um número de dados de uma característica
menor do que o mínimo estabelecido. Existem diversas possibilidades, como:

a. a remoção da variável que apresenta a micronumerosidade;
b. a recodificação da variável (quando possível);
c. a remoção dos dados que apresentam aquela característica em número 
insuficiente. 

A depender do procedimento adotado, o avaliador obterá um modelo diferente e a
implicância da adoção de cada procedimento será mostrada nos estudos de casos
apresentados. Presume-se, no entanto, a partir de uma leitura global da norma,
que a mesma sugere que a variável **e** os dados sejam removidos do modelo, pois
com a remoção apenas da variável e a inclusão dos dados com características
diferentes no modelo, a hipótese da homoscedasticidade dos resíduos,
normalmente, não se verifica, como será mostrado, e a norma também veda a
utilização de modelos em que as hipóteses da inferência clássica não se cumpram,
de acordo com o *caput* do item A.2.

## Inexistência de fatores de homogeinização

Ficou claro durante o [XX Cobreap](http://www.cobreap.com.br/2019/) que grande
parte dos avaliadores se utiliza do CA para resolver um dos maiores problemas da
prática atual da Engenharia de Avaliações, que é a falta de dados de transações,
o que implica na impossibilidade do cálculo de um fator oferta. A imensa maioria
dos Avaliadores se valem de uma pesquisa de dados ofertados, chegando assim a um
modelo para os preços de oferta, que infelizmente não corresponde a um modelo de
preços de venda dos imóveis.

A atual normativa não permite a aplicação de um fator oferta aos dados
pesquisados, a menos que este fator seja deduzido com a utilização de
metodologia científica.

No entanto, um modelo econométrico proposto por @horowitz permite a previsão de
preços de venda a partir de preços de oferta mais precisamente do que os que
seriam obtidos com um modelo hedônico elaborado à partir dos próprios dados de
venda.

Segundo Horowitz [-@horowitz, 124-125], o modelo econométrico por ele proposto
pode prever os preços de vendas a partir dos preços de oferta com uma erro médio
quadrático de apenas \$2.960, enquanto que com um modelo hedônico elaborado a
partir dos próprios dados de venda foi obtido um erro de \$10.361, ou seja, um 
erro médio muito maior do que o erro médio obtido com o modelo econométrico 
proposto.

Está fora do escopo deste trabalho detalhar a abordagem de @horowitz. Contudo, a
existência de um método capaz de prever preços de venda de imóveis a partir
apenas de dados de oferta, e com melhor precisão do que um modelo hedônico
elaborado com os próprios dados de venda é um fator a menos em favor da
utilização do CA do avaliador. Estudos devem ser levados a cabo e possivelmente
o modelo tenha que ser adaptado para se ajustar à realidade da prática da
Engenharia de Avaliações no Brasil, porém a existência de tal abordagem não pode
permanecer completamente ignorada como é hoje na Engenharia de Avaliações.

## Falta de significância dos regressores

Um dos pontos polêmicos da NBR 14.653-02 consiste na adoção de graus de 
fundamentação de modelos de regressão linear. Entre os critérios utilizados para
o enquadramento dos modelos nos diversos graus de fundamentação está o nível de
significância máxima para a rejeição da hipótese nula de cada regressor. Está
além do escopo deste artigo uma crítica pormenorizada a este critério, porém
deve-se salientar que este tipo de análise de importância de regressores à
partir dos p-valores dos testes de hipótese tem sido muito contestada entre os
estatísticos [ver @matloff2017, 349; @ASA].

## Viés devido à omissão de variável

Nesta subseção serão apresentados aspectos teóricos a respeito da omissão de 
variáveis relevantes de um modelo de regressão, independentemente dos motivos que
levem a esta omissão, seja por escassez de dados de mercado, seja por falta de
significância do regressor.

Segundo Matloff [-@matloff2017, 24], adicionando mais variáveis independentes a
um modelo se está a reduzir o viés do modelo.

Em tese, qualquer coisa que influencie o valor da variável dependente e não
esteja presente no modelo é absorvido pelo termo de erro (variação não-explicada
pelo modelo), que se assume estar não-correlacionado com os regressores
($\mathbb{E}[\varepsilon|X] = 0$). No entanto, se houver algum grau de correlação
entre a variável omitida e as variáveis presentes, como os efeitos da variável
omitida são absorvidas pelo termo de erro, a hipótese de independência dos 
resíduos não será mantida. Segundo Matloff [-@matloff2017, 25], um modelo assim
é chamado pelos economistas de modelo mal-especificado (*misspecified*), 
enquanto os estatísticos tratam este tipo viés como viés de modelagem (*model bias*).

De acordo com Matloff [-@matloff2017, 25], no entanto, isto não quer dizer que
se trata de um viés que tenha sido adicionado deliberadamente ao modelo, apenas
quer dizer que existe no modelo um viés sistêmico, que é permanente e não
desaparece, por mais que aumente-se o tamanho da amostra.

## Sobreajuste 

O sobreajuste ou *overfitting* em estatística é uma prática que consiste em
elaborar um modelo qualquer de maneira tão complexa que, ao invés de captar o
sinal, capta o ruído [@matloff2017, 24]. 

A prática, então, de se adicionar variáveis ao modelo para reduzir o viés da
estimação, como visto na subseção anterior, tem um limite: a introdução de uma
variável, ao diminuir o viés, também aumenta a variância das estimativas dos
coeficientes do modelo. Em um determinado ponto, o benefício da adição de 
variáveis ao modelo será menor do que a maior variabilidade que ocorrerá na 
estimação, o que é chamado de *overfitting* [@matloff2017, 24].

Segundo Matloff [-@matloff2017, 24], para qualquer estimador estatístico $\hat
\theta$ com variância finita, pode ser mostrado que:

\begin{equation} \label{eq:tradeoff}
MSE(\hat \theta) = Var(\hat \theta) + B^2(\hat \theta)
\end{equation}

Onde $MSE(\hat\theta)$ é o erro médio quadrático associado ao estimador, 
$Var(\hat\theta)$ é a variância do estimador e $B^2(\hat\theta)$ é o quadrado do
viés do estimador.

Segundo Matloff [-@matloff2017, 25], a equação \ref{eq:tradeoff} mostra que,
adicionando variáveis ao estimador de regressão linear, reduz-se o termo
$B^2(\hat \theta)$, porém ao custo do aumento da variância ($Var(\hat\theta)$) e
vice-versa, ao se remover variáveis do modelo, se está aumentando o viés do 
modelo, reduzindo, porém sua variância. De acordo com Matloff pode ser até
benéfico remover variáveis de um modelo com o intuito de reduzir a variância do
estimador, ao custo de aceitar um pouco de viés [@matloff2017, 25].

Um bom exemplo para o entendimento do problema pode ser encontrado em
@matloff2017 [p. 342-343], reproduzido abaixo:

Supondo uma amostra com alturas de meninos e meninas, estimar as alturas médias
de ambas as populações, com variância conhecida igual a $\sigma^2$. De acordo 
com Matloff, os estimadores naturais seriam:

\begin{equation} \label{eq:boys}
\hat\mu_1 = \frac{1}{n}\sum_{i=1}^{n}X_i
\end{equation}

\begin{equation} \label{eq:girls}
\hat\mu_2 = \frac{1}{n}\sum_{i=1}^{n}Y_i
\end{equation}

Porém, se o número de dados da amostra é pequeno, pode ser melhor simplificar o 
modelo e utilizar um único estimador para ambos os grupos:

\begin{equation} \label{eq:all}
\check \mu_i = \frac{1}{2}(\bar X + \bar Y), \ i = 1,2
\end{equation}

O critério para a escolha do melhor estimador é o erro médio quadrático (MSE).

Ocorre que o erro médio quadrático para os estimadores das equações 
\ref{eq:boys} e \ref{eq:girls} é igual à variância dos estimadores, dado que 
ambos são estimadores não-viesados ($B(\hat \mu_1) = B(\hat \mu_2) = 0$):

\begin{equation} \label{eq:mse1}
MSE(\hat\mu_1) + MSE(\hat\mu_2) = 2 Var(\hat \mu_i) = 2 \frac{\sigma^2}{n}
\end{equation}

Já para os estimadores $\check \mu_i$ a soma dos seus erros médios quadráticos
pode ser vista na equação \ref{eq:mse2} [^1]

\begin{equation} \label{eq:mse2}
MSE(\check\mu_1) + MSE(\check\mu_2) = \frac{\sigma^2}{n} + \frac{1}{2}(\mu_1 - \mu_2)^2
\end{equation}

[^1]: Obtido através da soma das variâncias e viés quadrados dos estimadores, 
como pode ser visto em @matloff2017 [p. 386-387].

Desta maneira, para saber qual o melhor estimador, deve-se comparar os valores
dos erros médios quadráticos obtidos nas equações \ref{eq:mse1} e \ref{eq:mse2}.

Caso:

\begin{equation} \label{eq:mseCompare}
2\frac{\sigma^2}{n} < (\mu_1-\mu_2)^2 
\end{equation}

Adotam-se os estimadores naturais. Caso contrário, mais vale a pena adotar o 
estimador único para ambos os grupos.

Deve-se ter em conta, observando-se a equação \ref{eq:mseCompare}, que:

1. se a diferença entre as médias $\mu_1$ e $\mu_2$ é pequena, o estimador único é bem próximo da realidade;
2. se o número de dados $n$ é pequeno, não há dados suficientes para se estimar com precisão os dois estimadores em separado;
3. se a variância da população é alta, também será preciso mais dados para a estimação em separado das duas médias.

Segundo Matloff [-@matloff2017, p. 344], este exemplo é um problema trivial de
regressão, onde deve-se escolher entre um modelo nulo ($p = 0$), e um modelo 
mais elaborado, com um regressor ($p = 1$), a saber, a variável dicotômica que 
indica se tratar de um dado de altura de menino ou menina.

Ainda de acordo com Matloff [-@matloff2017, p. 344], isto pode ser estendido ao
contexto genérico de modelos de regressão e classificação, com $p$ regressores e
$n$ observações: se $p$ é grande e/ou $n$ é pequeno, pode ser desejável utilizar
um modelo mais simples, omitindo alguns regressores em que o valor de $\beta$ 
seja negligenciável.

De acordo com Tukey e outro trabalho mais recente de Portnoy [*apud*
@matloff2017, p.344], via de regra, devem existir no máximo $\sqrt{n}$
regressores em um modelo de regressão para se evitar o sobreajuste do modelo.

# Estudos de Casos

Neste trabalho foram elaborados dois estudos de casos. 

No primeiro estudo de caso, que visa explorar os efeitos da omissão de variáveis
relevantes nos modelos de regressão linear, foram feitas quatro simulações,
variando o efeito da majoração dos valores de lotes em situação de esquina, em
relação aos lotes em situação de meio de quadra.

Foi elaborado ainda um segundo estudo de caso visando obter reflexões acerca da
utilização do CA quando, pelo contrário, não existem variáveis **relevantes** 
omitidas, ainda que haja variabilidade na amostra, o que também é normal que 
aconteça.

## Estudo de Caso 1 -- Viés devido à omissão de variável relevante

Neste Estudo de Caso foram elaborados quatro simulações de dados aleatórios para 
discussão de alguns fatos que são ilustrados com a aplicação de diferentes 
abordagens para o tratamento dos dados.

Para os quatro casos, os dados do Valor Unitário de cada lote (VU) foram 
criados através da seguinte equação de regressão (da população), conforme
equação \ref{eq:generic}:

\begin{equation} \label{eq:generic}
VU = \beta_0 + \beta_1 \cdot Area + \beta_2 \cdot Situacao + \varepsilon
\end{equation}

Onde $\varepsilon \sim \mathcal{N}(0, \sigma^2)$. Para os diversos casos foram
variados os valores dos coeficientes da população $\beta_i$ utilizados para a
geração de dados, de maneira a salientar o comportamento dos diversos modelos
ajustados tanto na estimação dos coeficientes ($\hat\beta_i$), quando na 
elaboração de previsões sobre um lote de referência.

A vantagem de se trabalhar com dados gerados é que se conhece *a priori* o valor
dos coeficientes ($\beta_i$) da população, já que estes estão pré-definidos.
Obviamente que, com a inclusão de um ruído ($\varepsilon$), no ajuste dos modelos
de regressão aos dados gerados, não são obtidos para os coeficientes ajustados
($\hat \beta_i$) exatamente os mesmos valores dos coeficientes populacionais
($\beta_i$) utilizados para a geração dos dados. Mas se o modelo estiver bem
especificado, os valores estimados para os coeficientes devem ser próximos dos
coeficientes utilizados para a geração dos dados, ou seja, $\hat \beta_i \approx
\beta_i$.

Em todos os casos foram gerados dados (propositalmente) em número insuficiente 
($<3$) para o caso dos lotes em situação de esquina.

Foram estudadas, então, as consequências da utilização de três diferentes tipos
de abordagens:

- O ajuste de um modelo de regressão com a inclusão de todos os dados, porém com
a omissão da variável `situacao`, visando emular o caso previsto na definição de 
CA, de omissão de variável relevante do modelo devido à escassez
de dados de mercado;

- O ajuste de um modelo de regressão com a exclusão dos dados de esquina, de 
maneira a se obter um modelo ajustado em cima de uma amostra homogênea, isto é,
um amostra onde todos os dados possuem as mesmas características em relação à
variável `situacao`.

- O ajuste de um modelo de regressão com a inclusão de todos os dados e todas as
variáveis, apesar da recomendação em contrário da NBR 14.653-02.

### Mercado 1

```{r dadosEx1, echo = FALSE}
set.seed(seed)
area <- c(360, 360, 360, 360, 480, 480, 360, 360, 480, 480)
situacao <- c(rep(0, 4), rep(1, 2), rep(0, 4))
VU <- 5000 - 5*area + 250*situacao + rnorm(10, 0, epsilonsd)
dados <- data.frame(VU, Area = area, Situacao = factor(situacao))
```

Para este exemplo os dados foram gerados através da equação \ref{eq:ex1}.

\begin{equation} \label{eq:ex1}
VU = 5000 - 5 \cdot Area + 250 \cdot Situacao + \varepsilon
\end{equation}

Onde $\varepsilon \sim \mathcal{N}(0, \,200^2)$. 

Neste exemplo, seja o caso de se avaliar um lote urbano de esquina com 480$m^2$,
baseado na amostra exibida na tabela \ref{tab:ex1}, obtida com as simulações,
onde `Situacao` é uma variável dicotômica que diferencia os imóveis em situação
de meio de quadra (0) dos imóveis de esquina (1).

```{r}
xtable(dados, 
       caption = "Dados para M. 1.",
       label = "tab:ex1",
       digits = 0,
       align = rep("c", 4)) %>%
  xtable2kable() %>%
  kable_styling(latex_options = "striped",
                position = "float_right")
```

De acordo com a NBR 14.653-02, como estão disponíveis apenas 2 dados de mercado
em situação de esquina, não seria possível a utilização da variável `Situacao`,
devido à micronumerosidade. Neste tipo de situação (escassez de dados de
mercado), a norma permite a utilização do CA.

Ou seja, segundo a NBR 14.653-02 leva a crer, poderia ser elaborado um modelo
com todos os dados amostrais, com a inclusão apenas da variável `Area`,
omitindo-se a variável `Situacao`e utilizar o CA para majorar o valor estimado
do lote pelo modelo, por este estar em situação de esquina, *desde que a
amplitude de até mais ou menos 15% seja suficiente para absorver as influências
não consideradas e que os ajustes sejam justificados*.

```{r, echo = FALSE}
#fit_a <- lmrob(VU ~ Area, data = dados)
fit_a <- lm(VU ~ Area, data = dados)
fit1_a <- lm(VU ~ Area, dados, subset = -c(5,6), x = TRUE, y = TRUE)
fit2_a <- lm(VU ~ Area + Situacao, dados, x = TRUE, y = TRUE)
```

```{r}
# Adjust standard errors
cov1         <- vcovHC(fit_a, type = "HC3")
robust_se    <- sqrt(diag(cov1))
```

```{r, results='asis', echo = FALSE}
stargazer::stargazer(fit_a, fit1_a, fit2_a, label = "tab:tab1", 
                     title = "Comparação de modelos para o Ex. 1.",
                     type = type, header = FALSE, table.placement = "H",
                     ci = TRUE, ci.level = .80, report = "vcst*", single.row = T,
                     intercept.bottom = FALSE, intercept.top = TRUE,
                     decimal.mark = ",", digit.separator = ".",
                     digits = 1, star.cutoffs = c(0.30, 0.20, 0.10),
                     # se = list(robust_se, NULL, NULL),
                     # notes = c("Reportados erros robustos para modelo da coluna 1."),
                     notes.label = "Notas:", font.size = "footnotesize")
# tab_model(fit_a, fit1_a, fit2_a,
#           dv.labels = c("Modelo 1", "Modelo 2", "Modelo 3"),
#           show.ci = 0.80,
#           show.stat = TRUE,
#           show.intercept = TRUE)
```

Na tabela \ref{tab:tab1} são mostrados os coeficientes dos três modelos
ajustados, isso fica claro: no primeiro modelo (coluna 1), foram utilizados
todos os dados e apenas a variável `Area`; no segundo modelo (coluna 2), foram
utilizados apenas os dados em situação de meio-de-quadra; e no terceiro modelo
(coluna 3) foram utilizados todos os dados e foi incluída a variável `Situacao`,
apesar da micronumerosidade.

Com a primeira abordagem (o modelo da coluna (1)), onde foram misturados dados
de esquina e de meio de quadra, esperava-se desvios em relação à 
homoscedasticidade dos resíduos.

No entanto, provavelmente devido à pequena diferença entre os valores dos lotes
em situação de esquina e dos lotes em situação de meio de quadra, a 
hipótese da homoscedasticidade não pôde ser rejeitada via teste de Breusch-Pagan:

```{r}
bptest(fit_a)
```

O que se percebe é que o primeiro modelo viesou para cima o coeficiente da 
variável `Area`. Ou seja, o efeito da `Situacao` do lote, que não foi incluso
no modelo, foi "absorvido" pela outra variável restante, ou seja, a variável 
`Area`. Isto ocorre porque a modelagem não respeitou um dos princípios da 
inferência clássica, que é a homogeneidade da amostra, haja vista que a 
amostra utilizada mistura imóveis em situação de meio de quadra e imóveis em
situação de esquina, sem uma variável que modele esta diferença entre os dados
amostrais.

Os outros dois modelos se aproximaram melhor dos coeficientes "reais" de 
regressão, ou seja, o valor dos coeficientes para a população ( 5000, -5,0 e
250). Isto se deve à homogeneidade da amostra, obtida ou através da exclusão dos
dados não-homogêneos, ou com a inclusão de todos os dados e variáveis
relevantes, em que pese estar em desacordo com o estabelecido pela NBR 14653-02.
Deve-se notar, contudo, que a estimação foi melhor para os coeficientes obtidos
com o terceiro modelo, haja vista o maior número de dados.

Pelo lado da estimação  dos coeficientes, portanto, não se recomenda a
utilização da primeira abordagem. A segunda abordagem é preferível à primeira,
porém a terceira abordagem é ainda mais precisa que a segunda.

```{r}
newx <- seq(min(dados$Area), max(dados$Area), by=2.5)
pred.int1 <- predict(fit_a, newdata = data.frame(Area = newx), 
                         interval = "prediction", level = 0.80)
pred.int1 <- data.frame(VU = pred.int1, Area = newx)
```

```{r, echo = FALSE}
# p_a <- Predict(fit_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
#                     interval = "confidence", level = .80, vcov.= hccm(fit_a))
p_a <- Predict(fit_a, newdata = data.frame(Area = 480, Situacao = factor(1)),
                    interval = "confidence", level = .80)
p_a_1 <- predict(fit_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
                 interval = "confidence", level = 0.80)
p1_a <- predict(fit1_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
                interval = "confidence", level = 0.80)
p2_a <- predict(fit2_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
                interval = "confidence", level = 0.80)
# P_a <- Predict(fit_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
#                interval = "prediction", level = 0.80, vcov.= hccm(fit_a))
P_a <- Predict(fit_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
               interval = "prediction", level = 0.80)
P1_a <- predict(fit1_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
                interval = "prediction", level = 0.80)
P2_a <- predict(fit2_a, newdata = data.frame(Area = 480, Situacao = factor(1)), 
                interval = "prediction", level = 0.80)
amp_a <- amplitude(P_a)
amp1_a <- amplitude(P1_a)
amp2_a <- amplitude(P2_a)
ca_a <- campo_arbitrio(p_a)
ca1_a <- campo_arbitrio(p1_a)
ca2_a <- campo_arbitrio(p2_a)
```

```{r figex1, fig.cap="Gráfico dos modelos para o primeiro mercado."}
plt1 <- ggplot(pred.int1, aes(x = Area, y = VU.fit)) +
  geom_point(data = dados, aes(x = Area, y = VU, color = Situacao), size = .5) +
  geom_smooth(data = pred.int1, aes(ymin = VU.lwr, ymax = VU.upr), 
              stat = "identity", size = .5, color = "orange") +
  geom_abline(intercept = coef(fit1_a)[1], slope = coef(fit1_a)[2], 
              color = "blue", size = .5) +
  geom_segment(aes(x = 360, y = 1.15*pred.int1[1, 1], 
                   xend = 480, yend = 1.15*pred.int1[49, 1]
                   ),
               color = "orange", lty = "ff", size = .5) +
  geom_segment(aes(x = 360, y = 0.85*pred.int1[1, 1], 
                   xend = 480, yend = 0.85*pred.int1[49, 1]
                   ),
               color = "orange", lty = "ff", lwd = .5) +
  scale_y_continuous(name = "VU", expand = c(0.025, 0.025), limits = c(2000, 4500)) +
  scale_x_continuous(expand = c(0.025, 0.025), limits = c(360, 480)) +
  scale_color_hue(name = 'Situação', labels = c('Meio de Quadra', 'Esquina')) +
  theme(legend.position = 'bottom', legend.direction = "horizontal",
        axis.text.x = element_text(color = "grey20", size = 8),
        axis.text.y = element_text(color = "grey20", size = 8))
```

A tabela 3 apresenta o comportamento das diversas abordagens para a previsão de
novos valores com a utilização dos modelos ajustados. Nesta tabela podem ser
vistos os valores para a estimativa central e para os limites inferiores e
superiores do IP (\@80%) e do CA, assim como a amplitude do CA. O valor teórico, 
obtido utilizando-se os coeficientes de regressão para a população ($\beta_i$) 
seria de `r reais()(5000 - 5*480 + 250)`.

Percebe-se desta maneira que para o **primeiro modelo**, o valor adicional do
lote em esquina já foi absorvido e já se encontra, em grande parte, na
estimativa central efetuada com o mesmo. No **segundo modelo**, que é um modelo
feito apenas para os dados de lotes em situação de meio de quadra, não há
qualquer influência de lotes em situação de esquina, ficando a previsão de
valores para lotes de esquina comprometida. E o **terceiro modelo**, apesar da
micronumerosidade, foi o que melhor estimou o lote em situação de esquina.

| Abordagem | Estimativa central     |$IP_{inf}$             | $IP_{sup}$              | Amplitude IP    | $CA_{inf}$       | $CA_{sup}$        |
|:----------|-----------------------:|----------------------:|------------------------:|----------------:|-----------------:|------------------:|
| 1         |`r brf(p_a[, "fit"])`   |`r brf(P_a[, "lwr"])`  |  `r brf(P_a[, "upr"])`  | `r brf(amp_a)`  | `r brf(ca_a[1])` | `r brf(ca_a[2])`  |  
| 2         |`r brf(p1_a[, "fit"])`  | `r brf(P1_a[, "lwr"])`|  `r brf(P1_a[, "upr"])` | `r brf(amp1_a)` | `r brf(ca1_a[1])`| `r brf(ca1_a[2])` |
| 3         |`r brf(p2_a[, "fit"])`  | `r brf(P2_a[, "lwr"])`|  `r brf(P2_a[, "upr"])` | `r brf(amp2_a)` | `r brf(ca2_a[1])`| `r brf(ca2_a[2])` |
Table: Comparação dos limites do IP e CA para os modelos do Ex. 1.

Deve-se notar que, para este caso, o CA é *suficiente para 
para absorver as influências não consideradas*, ou seja, com a adoção do limite
superior do CA é possível chegar e ultrapassar o valor 'real' do
imóvel, de R\$2.800,00.

### Mercado 2

```{r dadosEx2, echo = FALSE}
set.seed(seed)
area <- c(360, 360, 360, 360, 480, 480, 360, 360, 480, 480)
situacao <- c(rep(0, 4), rep(1, 2), rep(0, 4))
VU <- 5000 - 5*area + 390*situacao + rnorm(10, 0, epsilonsd)
dados <- data.frame(VU, Area = area, Situacao = factor(situacao))
```

Neste segundo exemplo, foram seguidos exatamente os mesmos passos do exemplo 
anterior. Contudo, para a geração dos valores, foi utilizado um peso maior para
os lotes de esquinam, conforme a equação \ref{eq:ex2}:

\begin{equation} \label{eq:ex2}
VU = 5000 - 5 \cdot area + 390 \cdot situacao + \varepsilon
\end{equation}

Onde $\varepsilon \sim \mathcal{N}(0, \,200^2)$ 

```{r}
xtable(dados, 
       caption = "Dados para M. 2.",
       label = "tab:ex2",
       digits = 0,
       align = rep("c", 4)) %>%
  xtable2kable() %>%
  kable_styling(latex_options = "striped", 
                full_width = F, 
                position = "float_right")
```

Os dados gerados encontram-se na tabela \ref{tab:ex2}. Deve-se reparar que,
aqui, erros à parte, foi adicionado R$390,00 ao valor de um lote em situação de
esquina em relação a um lote em situação de meio de quadra, o que significa um
adicional de exatamente 15% ao valor do lote-padrão de 480 $m^2$ em situação de
meio de quadra, que apresenta valor 'real' de R\$2.600,00. Ou seja, o valor do
lote que se pretende prever, de 480 $m^2$, em situação de esquina, neste mercado, 
terá valor 'real' de `r reais()(5000 - 5*480 + 390)`.

```{r, echo = FALSE}
# fit_b <- lmrob(VU ~ Area, data = dados)
fit_b <- lm(VU ~ Area, data = dados)
fit1_b <- lm(VU ~ Area, dados, subset = -c(5,6), x = TRUE, y = TRUE)
fit2_b <- lm(VU ~ Area + Situacao, dados, x = TRUE, y = TRUE)
```

Novamente, então, foram ajustados três modelos, como os descritos no exemplo
anterior.

Na tabela \ref{tab:tab2} são mostrados os coeficientes dos três modelos
ajustados. Novamente fica claro que: no primeiro modelo (coluna 1), os 
coeficientes ajustados estão viesados, no segundo e no terceiro modelos eles 
estão estimados corretamente, porém o terceiro modelo é mais preciso (menores
intervalos de confiança).

```{r}
# Adjust standard errors
cov1         <- vcovHC(fit_b, type = "HC3")
robust_se    <- sqrt(diag(cov1))
```

```{r, results='asis', echo = FALSE}
stargazer::stargazer(fit_b, fit1_b, fit2_b, label = "tab:tab2",
                     title = "Comparação de modelos para o Ex. 2.",
                     type = type, header = FALSE, table.placement = "H",
                     ci = TRUE, ci.level = .80, report = "vcst*", single.row = T,
                     intercept.bottom = FALSE, intercept.top = TRUE,
                     decimal.mark = ",", digit.separator = ".",
                     digits = 1, star.cutoffs = c(0.30, 0.20, 0.10),
                     # se = list(robust_se, NULL, NULL),
                     # notes = c("Reportados erros robustos para modelo da coluna 1."),
                     notes.label = "Notas:", font.size = "footnotesize")
# tab_model(fit_b, fit1_b, fit2_b,
#           dv.labels = c("Modelo 1", "Modelo 2", "Modelo 3"),
#           show.ci = 0.80,
#           show.stat = TRUE,
#           show.intercept = TRUE)
```

```{r, echo = FALSE}
# p_b <- Predict(fit_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
#                interval = "confidence", level = 0.80, vcov. = hccm(fit_b))
p_b <- predict(fit_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
               interval = "confidence", level = 0.80)
p1_b <- predict(fit1_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "confidence", level = 0.80)
p2_b <- predict(fit2_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "confidence", level = 0.80)
# P_b <- Predict(fit_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
#                interval = "prediction", level = 0.80, vcov. = hccm(fit_b))
P_b <- predict(fit_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
               interval = "prediction", level = 0.80)
P1_b <- predict(fit1_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80)
P2_b <- predict(fit2_b, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80)
amp_b <- amplitude(P_b)
amp1_b <- amplitude(P1_b)
amp2_b <- amplitude(P2_b)
ca_b <- campo_arbitrio(p_b)
ca1_b <- campo_arbitrio(p1_b)
ca2_b <- campo_arbitrio(p2_b)
```

A verificação da homoscedasticidade para a primeira abordagem, neste
caso, ainda se mantém:

```{r}
bptest(fit_b)
```

O intervalo de predição \@80% e os limites do CA para os três modelos na tabela
6. Deve-se notar que, em relação ao primeiro estudo de caso, a amplitude do IP
para o primeiro modelo aumentou, enquanto a amplitude do IP para o terceiro
modelo diminuiu. Na segunda abordagem, o que se obtêm é o mesmo modelo do
primeiro estudo de caso, portanto os intervalos de predição e de CA são
exatamente os mesmos do caso anterior.

```{r}
newx <- seq(min(dados$Area), max(dados$Area), by=2.5)
pred.int2 <- predict(fit_b, newdata = data.frame(Area = newx), 
                         interval = "prediction", level = 0.80)
pred.int2 <- data.frame(VU = pred.int2, Area = newx)
```

```{r figex2, fig.cap="Gráfico dos modelos para o segundo mercado."}
plt2 <- ggplot(pred.int2, aes(x = Area, y = VU.fit)) +
  geom_point(data = dados, aes(x = Area, y = VU, color = Situacao), size = .5) +
  geom_smooth(data = pred.int2, aes(ymin = VU.lwr, ymax = VU.upr), 
              stat = "identity", size = .5, color = "orange") +
  geom_abline(intercept = coef(fit1_b)[1], slope = coef(fit1_b)[2], 
              color = "blue", size = .5, lwd = 1) +
  geom_segment(aes(x = 360, y = 1.15*pred.int2[1, 1], 
                   xend = 480, yend = 1.15*pred.int2[49, 1]
                   ),
               color = "orange", lty = "ff") +
  geom_segment(aes(x = 360, y = 0.85*pred.int2[1, 1], 
                   xend = 480, yend = 0.85*pred.int2[49, 1]
                   ),
               color = "orange", lty = "ff") +
  scale_y_continuous(name = "VU", expand = c(0.025, 0.025), limits = c(2000, 4500)) +
  scale_x_continuous(expand = c(0.025, 0.025), limits = c(360, 480)) +
  theme(legend.position = 'bottom', legend.direction = "horizontal",
        axis.text.x = element_text(color = "grey20", size = 8),
        axis.text.y = element_text(color = "grey20", size = 8))
```


| Modelo | Estimativa central     |$IP_{inf}$             | $IP_{sup}$              | Amplitude IP    | $CA_{inf}$       | $CA_{sup}$        |
|:-------|-----------------------:|----------------------:|------------------------:|----------------:|-----------------:|------------------:|
| 1      |`r brf(p_b[, "fit"])`   |`r brf(P_b[, "lwr"])`  |  `r brf(P_b[, "upr"])`  | `r brf(amp_b)`  | `r brf(ca_b[1])` | `r brf(ca_b[2])`  |  
| 2      |`r brf(p1_b[, "fit"])`  | `r brf(P1_b[, "lwr"])`|  `r brf(P1_b[, "upr"])` | `r brf(amp1_b)` | `r brf(ca1_b[1])`| `r brf(ca1_b[2])` |
| 3      |`r brf(p2_b[, "fit"])`  | `r brf(P2_b[, "lwr"])`|  `r brf(P2_b[, "upr"])` | `r brf(amp2_b)` | `r brf(ca2_b[1])`| `r brf(ca2_b[2])` |
Table: Comparação dos limites do IP e CA para os modelos do Ex. 2.

### Mercado 3

```{r dadosEx3, echo = FALSE}
set.seed(seed)
area <- c(360, 360, 360, 360, 480, 480, 360, 360, 480, 480)
situacao <- c(rep(0, 4), rep(1, 2), rep(0, 4))
VU <- 5000 - 5*area + 780*situacao + rnorm(10, 0, epsilonsd)
dados <- data.frame(VU, Area = area, Situacao = factor(situacao))
```

```{r}
xtable(dados, 
       digits = 0,
       label = "tab:ex3",
       caption = "Dados para M. 3.",
       align = rep("c", 4))  %>%
  xtable2kable()  %>% 
  kable_styling(latex_options = "striped", 
                full_width = F, 
                position = "float_right")
```

Neste terceiro caso, foram seguidos exatamente os mesmos passos dos casos
anteriores. Contudo, para a geração dos valores, foi utilizado um peso maior
para os lotes de esquina, conforme a equação \ref{eq:ex3}:

\begin{equation} \label{eq:ex3}
VU = 5000 - 5 \cdot area + 780 \cdot situacao + \varepsilon
\end{equation}

Onde $\varepsilon \sim \mathcal{N}(0, \,200^2)$ 

Os dados gerados encontram-se na tabela \ref{tab:ex3}. Deve-se reparar que,
aqui, erros à parte, foi adicionado R$780,00 ao valor de um lote em situação de
esquina em relação a um lote em situação de meio de quadra, o que significa um
adicional de exatamente 30% ao valor do lote-padrão de 480 $m^2$ em situação de
meio de quadra, que apresenta valor 'real' de R\$2.600,00. Ou seja, o valor do
lote que se pretende prever, de 480 $m^2$, em situação de esquina, neste
mercado, terá valor 'real' de `r reais()(5000 - 5*480 + 780)`. Novamente, então, 
foram ajustados três modelos, como os descritos no exemplo anterior. 

```{r, echo = FALSE}
# fit_c <- lmrob(VU ~ Area, dados, x = TRUE, y = TRUE)
fit_c <- lm(VU ~ Area, dados, x = TRUE, y = TRUE)
fit1_c <- lm(VU ~ Area, dados, subset = -c(5,6), x = TRUE, y = TRUE)
fit2_c <- lm(VU ~ Area + Situacao, dados, x = TRUE, y = TRUE)
```

```{r}
# Adjust standard errors
cov1         <- vcovHC(fit_c, type = "HC3")
robust_se    <- sqrt(diag(cov1))
```

```{r, results='asis', echo = FALSE}
stargazer::stargazer(fit_c, fit1_c, fit2_c, label = "tab:tab3", 
                     title = "Comparação de modelos para o Ex. 3.",
                     type = type, header = FALSE, table.placement = "H",
                     ci = TRUE, ci.level = .80, report = "vcst*", single.row = T,
                     intercept.bottom = FALSE, intercept.top = TRUE,
                     decimal.mark = ",", digit.separator = ".",
                     digits = 1, star.cutoffs = c(0.30, 0.20, 0.10),
                     se = list(robust_se, NULL, NULL),
                     notes = c("Reportados erros robustos para modelo da coluna 1."),
                     notes.label = "Notas:", font.size = "footnotesize")
# tab_model(fit_c, fit1_c, fit2_c,
#           dv.labels = c("Modelo 1", "Modelo 2", "Modelo 3"),
#           show.ci = 0.80,
#           show.stat = TRUE,
#           show.intercept = TRUE)
```

Na tabela \ref{tab:tab3} são mostrados os coeficientes dos três
modelos ajustados. Novamente fica claro que: no primeiro modelo (coluna 1), os
coeficientes ajustados estão viesados, no segundo e no terceiro modelos eles
estão estimados corretamente, porém o terceiro modelo é mais preciso (menores
intervalos de confiança).

```{r}
newx <- seq(min(dados$Area), max(dados$Area), by=2.5)
pred.int3 <- predict(fit_c, newdata = data.frame(Area = newx), 
                         interval = "prediction", level = 0.80)
pred.int3 <- data.frame(VU = pred.int3, Area = newx)
```

```{r figex3, fig.cap="Gráfico dos modelos para o terceiro mercado."}
plt3 <- ggplot(pred.int3, aes(x = Area, y = VU.fit)) +
  geom_point(data = dados, aes(x = Area, y = VU, color = Situacao), size = .5) +
  geom_smooth(data = pred.int3, aes(ymin = VU.lwr, ymax = VU.upr), 
              stat = "identity", size = .5, color = "orange") +
  geom_abline(intercept = coef(fit1_c)[1], slope = coef(fit1_c)[2], 
              color = "blue", size = .5, lwd = 1) +
  geom_segment(aes(x = 360, y = 1.15*pred.int3[1, 1], 
                   xend = 480, yend = 1.15*pred.int3[49, 1]),
               color = "orange", lty = "ff") +
  geom_segment(aes(x = 360, y = 0.85*pred.int3[1, 1], 
                   xend = 480, yend = 0.85*pred.int3[49, 1]),
               color = "orange", lty = "ff") +
  scale_y_continuous(name = "VU", expand = c(0.025, 0.025), limits = c(2000, 4500)) +
  scale_x_continuous(expand = c(0.025, 0.025), limits = c(360, 480)) +
  theme(legend.position = 'bottom', legend.direction = "horizontal",
        axis.text.x = element_text(color = "grey20", size = 8),
        axis.text.y = element_text(color = "grey20", size = 8))
```

```{r, echo = FALSE}
p_c <- Predict(fit_c, newdata = data.frame(Area = 480, Situacao = factor(1)), 
               interval = "confidence", level = 0.80, vcov. = hccm(fit_c))
p1_c <- predict(fit1_c, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "confidence", level = 0.80)
p2_c <- predict(fit2_c, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "confidence", level = 0.80)
P_c <- Predict(fit_c, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80, vcov. = hccm(fit_c))
P1_c <- predict(fit1_c, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80)
P2_c <- predict(fit2_c, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80)
amp_c <- amplitude(P_c)
amp1_c <- amplitude(P1_c)
amp2_c <- amplitude(P2_c)
ca_c <- campo_arbitrio(p_c)
ca1_c <- campo_arbitrio(p1_c)
ca2_c <- campo_arbitrio(p2_c)
```

Com o aumento da diferença de valores médios para os lotes em situação de
esquina em relação aos lotes em situação de meio de quadra, com o modelo da
primeira abordagem a homoscedasticidade não pode ser verificada, segundo o teste
de Breusch-Pagan:

```{r}
bptest(fit_c)
```

O baixo p-valor encontrado indica que o teste rejeita a hipótese nula (da
homoscedasticidade). 

A presença de heteroscedasticidade também pode ser detectada visualmente através
da análise da Figura \ref{fig:hetero}: para os lotes de maior área (e menor VU),
a grande discrepância entre os resíduos dos lotes em situação de esquina
(resíduos positivos, pontos 5 e 6) e dos resíduos dos lotes em situação de meio
de quadra (resíduos negativos de menor área) fazem com que a variância dos erros
naquele ponto sejam maiores do que a variância dos lotes de maior área, causando
a heteroscedasticidade.

```{r hetero, fig.cap = "Gráfico de resíduos vs. valores ajustados."}
plot(fit_c, which = 1)
```

Ou seja, a análise dos resíduos do modelo indica uma estrutura presente nestes
resíduos. Como se sabe, esta estrutura ali presente deve-se à variável omitida:
como o modelo foi ajustado considerando dados de diferentes características sem
uma variável que represente esta mudança de característica, o valor do
coeficiente da variável `Area` tornou-se uma espécie de média ponderada entre a
redução real do do valor unitário devido ao aumento da área (para os dados de
meio de quadra) e a redução menor dos valores unitários que ocorre nos dados em
situação de esquina. Os erros, portanto, apesar de simétricos (há exatamente 2
dados de cada característica com 480 $m2$) serão maiores, em magnitude, para os
imóveis de 480 $m^2$ do que para os imóveis de 360 $m^2$, donde advém a
heteroscedasticidade. Na segunda abordagem, como os dados em situação de esquina
foram removidos junto com a variável, este modelo resulta homoscedástico (não 
mostrado).

Os intervalos de confiança e predição \@80% para os três modelos, bem como os
limites do CA podem ser vistos na tabela 8 [^4] abaixo:


| Modelo | Estimativa central     |$IP_{inf}$             | $IP_{sup}$              | Amplitude IP    | $CA_{inf}$       | $CA_{sup}$        |
|:-------|-----------------------:|----------------------:|------------------------:|----------------:|-----------------:|------------------:|
| 1      |`r brf(p_c[, "fit"])`   |`r brf(P_c[, "lwr"])`  |  `r brf(P_c[, "upr"])`  | `r brf(amp_c)`  | `r brf(ca_c[1])` | `r brf(ca_c[2])`  |  
| 2      |`r brf(p1_c[, "fit"])`  | `r brf(P1_c[, "lwr"])`|  `r brf(P1_c[, "upr"])` | `r brf(amp1_c)` | `r brf(ca1_c[1])`| `r brf(ca1_c[2])` |
| 3      |`r brf(p2_c[, "fit"])`  | `r brf(P2_c[, "lwr"])`|  `r brf(P2_c[, "upr"])` | `r brf(amp2_c)` | `r brf(ca2_c[1])`| `r brf(ca2_c[2])` |
Table: Comparação dos limites do IP e CA para os modelos do Ex. 3.

[^4]: O intervalos de predição para o modelo da primeira abordagem foram 
calculados com a utilização de erros robustos.

Deve-se notar que, com a primeira abordagem, como o modelo é viesado, o campo de
arbítrio ainda resultou suficiente para absorver os efeitos da variável omitida,
o que não acontece com a segunda abordagem. Para o terceiro modelo, novamente,
as previsões centrais são boas e o IP é pequeno.

### Mercado 4

```{r dadosEx4, echo = FALSE}
set.seed(seed)
area <- c(360, 360, 360, 360, 480, 480, 360, 360, 480, 480)
situacao <- c(rep(0, 4), rep(1, 2), rep(0, 4))
VU <- 5000 - 5*area + 1500*situacao + rnorm(10, 0, epsilonsd)
dados <- data.frame(VU, Area = area, Situacao = factor(situacao))
```

```{r}
xtable(dados, 
       digits = 0,
       label = "tab:ex4",
       caption = "Dados para M. 4.",
       align = rep("c", 4))  %>%
  xtable2kable()  %>% 
  kable_styling(latex_options = "striped", 
                full_width = F, 
                position = "float_right")
```

Neste quarto caso, foram seguidos exatamente os mesmos passos dos casos
anteriores. Contudo, para a geração dos valores, foi adotada uma majoração maior
para os lotes em situação de esquina, conforme \ref{eq:ex4}. O que se buscou foi
uma situação em que a amplitude do IP para a primeira
abordagem extrapole a amplitude do CA.

\begin{equation} \label{eq:ex4}
VU = 5000 - 5 \cdot Area + 1500 \cdot Situacao + \varepsilon
\end{equation}

Onde $\varepsilon \sim \mathcal{N}(0, \,200^2)$ 

Os dados gerados encontram-se na tabela \ref{tab:ex4}. Deve-se notar que os
valores das estimativas centrais para os lotes em estudo, de 480 $m^2$, em
situação de meio de quadra ou esquina, com este modelo, serão de  
`r reais()(5000 - 5*480)` e `r reais()(5000 - 5*480 + 1500)`, respectivamente. O
que se pretende é simular é se num mercado com uma maior variabilidade o campo
de arbítrio pode ser uma bom fator limitante. Novamente, então, foram ajustados 
três modelos, como os descritos no exemplo anterior.

Na tabela \ref{tab:tab4} são mostrados os coeficientes dos três modelos
ajustados. Novamente fica claro que: no primeiro modelo (coluna 1), os
coeficientes ajustados estão viesados, no segundo e no terceiro modelos eles
estão estimados corretamente, porém o terceiro modelo é mais preciso (menores
intervalos de confiança).

Deve-se notar ainda na tabela \ref{tab:tab4} que o modelo da primeira abordagem,
visto na coluna (1), apresentou coeficiente de ajuste baixíssimo e coeficiente
de correlação ajustado negativo. O teste de significância da variável
independente do modelo não foi significante nem para enquadrar o modelo no grau
I de fundamentação da NBR 14.653-02. Ainda assim este modelo faz boas previsões
se utilizado corretamente o IP. 

```{r, echo = FALSE}
# fit_d <- lmrob(VU ~ Area, data = dados)
fit_d <- lm(VU ~ Area, data = dados)
fit1_d <- lm(VU ~ Area, dados, subset = -c(5,6), x = TRUE, y = TRUE)
fit2_d <- lm(VU ~ Area + Situacao, dados, x = TRUE, y = TRUE)
```

```{r}
# Adjust standard errors
cov1         <- vcovHC(fit_d, type = "HC3")
robust_se    <- sqrt(diag(cov1))
```


```{r, results='asis', echo = FALSE}
stargazer::stargazer(fit_d, fit1_d, fit2_d, label = "tab:tab4", 
                     title = "Comparação de modelos para o Ex. 4.",
                     type = type, header = FALSE, table.placement = "H",
                     ci = TRUE, ci.level = .80, report = "vcst*", single.row = T,
                     intercept.bottom = FALSE, intercept.top = TRUE,
                     decimal.mark = ",", digit.separator = ".",
                     digits = 1, star.cutoffs = c(0.30, 0.20, 0.10),
                     se = list(robust_se, NULL, NULL),
                     notes = c("Reportados erros robustos para modelo da coluna 1."),
                     notes.label = "Notas:", font.size = "footnotesize")
# tab_model(fit_c, fit1_c, fit2_c,
#           dv.labels = c("Modelo 1", "Modelo 2", "Modelo 3"),
#           show.ci = 0.80,
#           show.stat = TRUE,
#           show.intercept = TRUE)
```

Já o modelo da segunda abordagem (coluna (2)) tem um coeficiente de ajuste muito
alto e o modelo tem grau III de fundamentação, segundo a NBR 14.653-02. No 
entanto, este modelo é totalmente inadequado para fazer previsões fora dos dados
da amostra, mesmo com a utilização do CA ou do IP.

```{r}
newx <- seq(min(dados$Area), max(dados$Area), by=2.5)
pred.int4 <- predict(fit_d, newdata = data.frame(Area = newx), 
                         interval = "prediction", level = 0.80)
pred.int4 <- data.frame(VU = pred.int4, Area = newx)
```

```{r figex4, fig.cap="Gráfico dos modelos para o quarto mercado."}
plt4 <- ggplot(pred.int4, aes(x = Area, y = VU.fit)) +
  geom_point(data = dados, aes(x = Area, y = VU, color = Situacao), size = .5) +
  geom_smooth(data = pred.int4, aes(ymin = VU.lwr, ymax = VU.upr), 
              stat = "identity", size = .5, color = "orange") +
  geom_abline(intercept = coef(fit1_d)[1], slope = coef(fit1_d)[2], 
              color = "blue", size = .5, lwd = 1) +
  geom_segment(aes(x = 360, y = 1.15*pred.int4[1, 1], 
                   xend = 480, yend = 1.15*pred.int4[49, 1]
                   ),
               color = "orange", lty = "ff") +
  geom_segment(aes(x = 360, y = 0.85*pred.int4[1, 1], 
                   xend = 480, yend = 0.85*pred.int4[49, 1]
                   ),
               color = "orange", lty = "ff") +
  scale_y_continuous(name = "VU", expand = c(0.025, 0.025), limits = c(2000, 4500)) +
  scale_x_continuous(expand = c(0.025, 0.025), limits = c(360, 480)) +
  theme(legend.position = 'bottom', legend.direction = "horizontal",
        axis.text.x = element_text(color = "grey20", size = 8),
        axis.text.y = element_text(color = "grey20", size = 8))
```


```{r, echo = FALSE}
p_d <- Predict(fit_d, newdata = data.frame(Area = 480, Situacao = factor(1)), 
               interval = "confidence", level = 0.80, vcov. = hccm(fit_d))
p1_d <- predict(fit1_d, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "confidence", level = 0.80)
p2_d <- predict(fit2_d, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "confidence", level = 0.80)
P_d <- Predict(fit_d, newdata = data.frame(Area = 480, Situacao = factor(1)), 
               interval = "prediction", level = 0.80, vcov. = hccm(fit_d))
P1_d <- predict(fit1_d, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80)
P2_d <- predict(fit2_d, newdata = data.frame(Area = 480, Situacao = factor(1)), 
              interval = "prediction", level = 0.80)
amp_d <- amplitude(P_d)
amp1_d <- amplitude(P1_d)
amp2_d <- amplitude(P2_d)
ca_d <- campo_arbitrio(p_d)
ca1_d <- campo_arbitrio(p1_d)
ca2_d <- campo_arbitrio(p2_d)
```

O intervalo de predição \@80% para os três modelos, bem como os 
limites do CA podem ser vistos na tabela 12 [^5] abaixo:


| Modelo | Estimativa central     | $IP_{inf}$             | $IP_{sup}$             | Amplitude IP   | $CA_{inf}$       | $CA_{sup}$        |
|:-------|-----------------------:|-----------------------:|-----------------------:|---------------:|-----------------:|------------------:|
| 1      |`r brf(p_d[, "fit"])`   | `r brf(P_d[, "lwr"])`  | `r brf(P_d[, "upr"])`  | `r brf(amp_d)` | `r brf(ca_d[1])` | `r brf(ca_d[2])`  |  
| 2      |`r brf(p1_d[, "fit"])`  | `r brf(P1_d[, "lwr"])` | `r brf(P1_d[, "upr"])` | `r brf(amp1_d)`| `r brf(ca1_d[1])`| `r brf(ca1_d[2])` |
| 3      |`r brf(p2_d[, "fit"])`  | `r brf(P2_d[, "lwr"])` | `r brf(P2_d[, "upr"])` | `r brf(amp2_d)`| `r brf(ca2_d[1])`| `r brf(ca2_d[2])` |
Table: Comparação dos limites do IP e CA para os modelos do Ex. 4.

[^5]: Os intervalos de predição e confiança para o modelo da primeira abordagem
foram calculados com a utilização de erros robustos.

Deve-se notar que, neste mercado, como a majoração do valor unitário de um lote 
devido a situação esquina é grande, com a primeira abordagem o CA 
resultou insuficiente para absorver os efeitos da variável omitida. A segunda 
abordagem segue com o mesmo modelo. Já  com o terceiro modelo, novamente, as 
previsões centrais são muito boas e o IP é pequeno.

Na primeira abordagem, deve-se notar que o IP do modelo 
contém o valor 'real' do lote, enquanto que o intervalo de valores dentro das
semi-amplitudes de $\pm$ 15% do CA não contém o valor 'real' do lote, já que o
valor real do lote é $\approx$ 18,5% superior à estimativa do valor central 
obtida com este modelo (`r brf(p_d[, "fit"])`).

### Resumo

Em suma, para quatro mercados diferentes (4 bairros diferentes, digamos), foram
testados três tipos de abordagens diferentes: 

1. A abordagem de se considerar todos os dados, porém excluindo a variável 
`situacao`, por conta da micronumerosidade;

2. A abordagem de se desconsiderar, além das variáveis, também os dados em
situação de esquina, chegando-se assim a um modelo apenas para os lotes em
situação de meio de quadra;

3. A abordagem de utilizar-se todos os dados e todas as variáveis, apesar disso 
ir de encontro com a norma vigente, por conta da micronumerosidade.

```{r modelos, fig.cap="Gráficos dos modelos para os quatro mercados.", out.width="100%"}
prow <- plot_grid(
  plt1 + theme(legend.position="none"), 
  plt2 + theme(legend.position="none"), 
  plt3 + theme(legend.position="none"), 
  plt4 + theme(legend.position="none"), 
  hjust = -1,
  nrow = 2,
  labels = "AUTO")
legend <- get_legend(
  # create some space to the left of the legend
  plt1 + theme(legend.box.margin = margin(0, 0, 0, 0))
)
plot_grid(prow, legend, ncol = 1, rel_heights = c(1, .1))
```

Os gráficos dos modelos para os quatro mercados podem ser vistos na Figura
\ref{fig:modelos}. Nela podem-se ver os dados do modelo acompanhados das retas
de regressão para a primeira abordagem (linha cheia, em laranja) e para as
segunda abordagem (em azul). Em cinza pode-se ver as bandas do IP para o modelo
da primeira abordagem. As linhas laranjas tracejadas representam os limites do
CA para a primeira abordagem. Deve-se notar que, como da própria definição de
IP, este possui a propriedade de conter 80% dos dados previstos para o mercado,
de maneira que, se a variável `Situacao` não está presente no modelo, o IP
deverá se alargar de maneira a conter 80% dos dados. Num modelo bem ajustado
esse intervalo é menor, já que outra variável estaria explicando a diferença de
valores entre dados em situação de esquina e meio de quadra.

Em todos os mercados (bairros) **a terceira abordagem mostrou-se superior**,
obtendo-se uma valor de estimativa central mais próxima do valor "real", e um
IP mais estreito, além de um modelo com estimação adequada para os coeficientes.

```{r}
# p <- plot_ly(data = dados, x = ~Area, y = ~Situacao, z = ~VU, opacity = 0.6) %>% 
#   add_markers()
# 
# p %>% add_surface(z = ~plane, x = ~Area, y = ~Situacao, showscale = FALSE) %>% layout(showlegend = FALSE)
#coplot(VU ~ Area|Situacao, data = dados, panel=panel.car, col="red")
```


```{r comparacao}
df <- data.frame(Mercado = c(rep("A", 3), rep("B", 3), rep("C", 3), rep("D", 3)),
                 Abordagem = rep(c(1,2,3), 4),
                 `Estimativa Central` = c(p_a[, "fit"], p1_a[, "fit"], p2_a[, "fit"],
                                          p_b[, "fit"], p1_b[, "fit"], p2_b[, "fit"],
                                          p_c[, "fit"], p1_c[, "fit"], p2_c[, "fit"],
                                          p_d[, "fit"], p1_d[, "fit"], p2_d[, "fit"]),
                 `IP superior` = c(P_a[, "upr"], P1_a[, "upr"], P2_a[, "upr"],
                                   P_b[, "upr"], P1_b[, "upr"], P2_b[, "upr"],
                                   P_c[, "upr"], P1_c[, "upr"], P2_c[, "upr"],
                                   P_d[, "upr"], P1_d[, "upr"], P2_d[, "upr"]),
                 `CA superior` = c(ca_a[2], ca1_a[2], ca2_a[2],
                                   ca_b[2], ca1_b[2], ca2_b[2],
                                   ca_c[2], ca1_c[2], ca2_c[2],
                                   ca_d[2], ca1_d[2], ca2_d[2]),
                 `Valor Real` = c(rep(2850, 3), rep(2990, 3), rep(3380, 3), rep(4100, 3))
                 )
kable(df,
      caption = "IP vs. CA em vários mercados, com diferentes abordagens.",
      booktabs = TRUE,
      digits = 1,
      format.args = list(big.mark = ".", decimal.mark = ","),
      col.names = c("Mercado", "Abordagem", "Central", "IP superior", 
                    "CA superior", "Valor 'real'")) %>%
  add_header_above(c(" ", " ", "Estimativa" = 3, " "), bold = T) %>% 
  column_spec(1, bold = T) %>%
  row_spec(0, bold = T) %>% 
  row_spec(c(1:3, 7:9) -1, extra_latex_after = "\\rowcolor{gray!6}") %>% 
  collapse_rows()
```


Com a **segunda abordagem**, obtem-se sempre o mesmo modelo, com mesmos
intervalos de predição e mesmos  campos de arbitrio, haja vista que o que se
altera nos três mercados é apenas o efeito de majoração devido à situação de
esquina, cujos dados são excluídos nesta abordagem. Apesar deste modelo obter
coeficientes ajustados corretamente para as demais variáveis, ele não é bom para
se efetuar previsões para dados com características diferentes dos dados
efetivamente utilizados na amostra. A adoção do CA  ou do IP só pode ser feita 
completamente no escuro, sem que exista nada que possa embasar a magnitude da 
majoração dos valores das estimativas centrais, que são válidas apenas para os
tipos de dados permanecentes na amostra, no caso, os dados em situação de 
meio de quadra.

| Mercado   | Erro $\hat Y$                   | Erro $\hat Y_{sup}$             | Erro $CA_{sup}$            |
|:---------:|--------------------------------:|--------------------------------:|---------------------------:|
| A         | `r pct(p1_a[, "fit"]/2850 - 1)` | `r pct(P1_a[, "upr"]/2850 - 1)` | `r pct(ca1_a[2]/2850 - 1)` |
| B         | `r pct(p1_b[, "fit"]/2990 - 1)` | `r pct(P1_b[, "upr"]/2990 - 1)` | `r pct(ca1_b[2]/2990 - 1)` |
| C         | `r pct(p1_c[, "fit"]/3380 - 1)` | `r pct(P1_c[, "upr"]/3380 - 1)` | `r pct(ca1_c[2]/3380 - 1)` |
| D         | `r pct(p1_d[, "fit"]/4100 - 1)` | `r pct(P1_d[, "upr"]/4100 - 1)` | `r pct(ca1_d[2]/4100 - 1)` |
Table: Erros (%) obtidos com a utilização da segunda abordagem.

\newpage

Finalmente, com a **primeira abordagem**, apesar dos coeficientes serem
estimados de maneira muito pobre, viesados por conta do efeito da variável
relevante omitida, o modelo obtido é razoavelmente bom para fazer previsões,
desde que se faça o uso correto do intervalo de predição. Deve-se ter em mente
que o modelo não prevê como estimativa de valor central nem o valor para o lote
em situação de meio de quadra, nem o valor do lote em situação de esquina, mas
algo entre as duas situações. Para se prever valores dos lotes de meio de quadra
deve-se minorar os valores das estimativas centrais enquato que para os lotes de
esquina, deve-se majorá-las[^6].

[^6]: Essentially, all models are wrong, but some are useful [@Box1986, 424]. . 

É possível mostrar que os modelos da primeira abordagem, independente do
mercado, não apresentam homoscedasticidade, considerado o teste de
Breusch-Pagan, enquanto os modelos da segunda e terceira abordagem passam no
teste. Contudo, com os modelos da primeira abordagem é possível fazer boas 
previsões, enquanto que com os modelos da segunda abordagem isto não é possível.

Com a adoção do limite superior do IP, porém, o erro cometido com a primeira
abordagem é muito pequeno, independente do mercado estudado, como ilustra a
tabela abaixo. Os erros que se cometeriam ao se utilizar o limite superior do
CA, comum na prática da engenharia de avaliações, é muito maior do que o erro
cometido com a adoção do limite superior do IP.


| Mercado   | Erro $\hat Y$                  | Erro $\hat Y_{sup}$            | Erro $CA_{sup}$           |
|:---------:|-------------------------------:|-------------------------------:|--------------------------:|
| A         | `r pct(p_a[, "fit"]/2850 - 1)` | `r pct(P_a[, "upr"]/2850 - 1)` | `r pct(ca_a[2]/2850 - 1)` |
| B         | `r pct(p_b[, "fit"]/2990 - 1)` | `r pct(P_b[, "upr"]/2990 - 1)` | `r pct(ca_b[2]/2990 - 1)` |
| C         | `r pct(p_c[, "fit"]/3380 - 1)` | `r pct(P_c[, "upr"]/3380 - 1)` | `r pct(ca_c[2]/3380 - 1)` |
| D         | `r pct(p_d[, "fit"]/4100 - 1)` | `r pct(P_d[, "upr"]/4100 - 1)` | `r pct(ca_d[2]/4100 - 1)` |
Table: Erros (%) obtidos com a utilização da primeira abordagem.

## Estudo de Caso 2 -- Avaliação intervalar

Os estudos de casos aqui mostrados ainda podem fornecer pistas para uma adoção
de um intervalo admissível de valores condizente com a teoria estatística.

Nos casos apresentados, porém, trabalhou-se com poucas variáveis, portanto a
omissão de uma das variáveis já impacta fortemente o modelo e as previsões com
ele obtidas. Na prática, com mais variávieis explicando o mercado, pode ser que
a omissão de uma variável tenha um impacto mais leve tanto na estimação dos
coeficientes do modelo, quanto nas previsões. Assim, pode-se imaginar que a 
omissão de uma variável do modelo possa levar a valores estimados dentro do 
IP, porém não nos seus extremos, como nos casos apresentados.

Imagine-se que se saiba previamente que a amostra de trabalho não seja
totalmente homogênea (na prática, ela quase nunca será). Para melhor ilustrar
isto, imagine-se construir um modelo sobre uma amostra de um mercado de
apartamentos em uma zona central qualquer de uma cidade, onde se saiba que
existem na amostra alguns imóveis com características melhores que a média
(melhor posição solar, melhor ventilação, melhor vista), porém estas
características não foram contempladas no modelo - afinal não se pode fazer um
modelo que contenha absolutamente todas as características, pois estas seriam
muitas e o número de dados da amostra é sempre limitado. Além do mais, o que se
obteria com a modelagem de todas as características da amostra seria um modelo
com sobreajuste, que não serviria para fazer previsões de valores para dados
fora da amostra.

```{r dadosEx5, echo = FALSE}
set.seed(seed)
area <- rnorm(150, mean = 200, sd = .25*epsilonsd)
padrao <- rep(c(1, 2, 3), each = 50)
VU <- 5000 - 5*area + 250*padrao + rnorm(99, 0, epsilonsd)
dados <- data.frame(VU, Area = area, Padrao = factor(padrao))
```
```{r}
fit <- lm(VU ~ Area + Padrao, data = dados)
```

Foram simulados dados conforme a equação \ref{eq:ex5}

\begin{equation} \label{eq:ex5}
VU = 5000 - 5 \cdot Area + 250 \cdot Padrao + \varepsilon
\end{equation}

Onde $\varepsilon \sim \mathcal{N}(0, \,200^2)$ 

É sabido que existe correlação entre as variáveis no Mercado Imobiliário. Se
um imóvel tem uma vista privilegiada, por exemplo, ele deverá ter um padrão de
acabamento melhor também. 

Imagine-se agora que se deva prever o valor de um novo imóvel com padrão médio,
com outras características não modeladas um pouco melhores que a média (uma 
posição solar melhor, uma vista um pouco mais aberta), de maneira que o avaliador
opte por utilizar, ao invés da estimativa central, o limite superior do IP.

Os gráficos do modelo ajustado com os dados simulados podem ser vistos na 
Figura \ref{fig:modelo}

```{r modelo, fig.cap="Modelo ajustado para apartamentos.", fig.width = 9, out.width="80%"}
p <- plotmod(fit, level = 0.80, interval = "prediction")
p
```

```{r}
newdata <- data.frame(Area = c(150, 150, 150), Padrao = factor(c(1, 2, 3)))
p <- predict(fit, newdata = newdata, interval = "prediction", level = 0.80)
ca <- campo_arbitrio(p)
```


Para os dados simulados, este valor seria igual a `r brf(p[2, "upr"])`. Qual 
seria, então, um intervalo razoável de valores admissíveis?

Como limite inferior, pode-se dizer que, com certeza, o imóvel não está abaixo
da média. Logo, a estimativa de valor central seria um bom indicador de um 
limite inferior para os valores admissíveis: `r brf(p[2, "fit"])`. E quanto ao
limite superior? Neste caso, seria razoável adotar o limite superior do CA. Já
que a NBR não permite que se extrapole os 15% do CA, este é o limite superior do
intervalo. Caso o limite superior do IP ultrapasse os 15%, este modelo não seria
aceito, mas caso o limite superior do IP esteja dentro do CA, é razoável que o
intervalo de valores admissíveis esteja entre o valor central e o limite superior
do CA, neste caso, `r brf(ca[2, "C.A.S."])`. Em sum, adotando-se os critérios
acima, o resultado da avaliação seria um intervalo como o abaixo:

`r brf(p[2, "fit"])` $\leq$ `r brf(p[2, "upr"])` $\leq$ `r brf(ca[2, "C.A.S."])`

Por outro lado, se o que se pretende com o modelo seja avaliar um imóvel de
**alto padrão**, também com vista e posição solar privilegiada, etc., segundo os
mesmos critérios utilizados para o imóvel de padrão médio, teria-se:

`r brf(p[3, "fit"])` $\leq$ `r brf(p[3, "upr"])` $\leq$ `r brf(ca[3, "C.A.S."])`

E, finalmente, para um imóvel de baixo padrõa, acima da média em relação às 
outras características, teria-se:

`r brf(p[1, "fit"])` $\leq$ `r brf(p[1, "upr"])` $\leq$ `r brf(ca[1, "C.A.S."])`

Em suma, acredita-se que uma boa melhoria em termos de normatização seria obtida
se a NBR 14.653 estabelecesse que, para a adoção de valores fora da estimativa
central seja adotada uma amplitude máxima do IP (\@80%) de 30% e que a adoção de
um valor diferente da estimativa central seja feita dentro do IP. Além disto,
que seja reportado um intervalo de valores admissíveis que seja coerente, com
valor máximo igual à semi-amplitude do CA e valor mínimo igual à estimativa de
valor central (e vice-versa: se for necessário aplicar uma minoração do valor
central, que se utilize que como valor mínimo o limite inferior do CA e se adote
o valor central como limite superior do intervalo de valores admissíveis).

Outra opção seria adotar um intervalo admissível sempre simétrico, com
semi-amplitude igual à menor distância entre o valor adotado e o valor central
ou ao valor do limite superior/inferior do CA. Neste caso, obteríam-se três 
intervalos simétricos, ao invés dos intervalos reportados acima:

`r brf(p[2, "fit"])` $\leq$ `r brf(p[2, "upr"])` $\leq$ `r brf(p[2, "upr"] + (p[2, "upr"] - p[2, "fit"]))`  

`r brf(p[3, "fit"])` $\leq$ `r brf(p[3, "upr"])` $\leq$ `r brf(p[3, "upr"] + (p[3, "upr"] - p[3, "fit"]))`  

`r brf(p[1, "fit"])` $\leq$ `r brf(p[1, "upr"])` $\leq$ `r brf(p[1, "upr"] + (p[1, "upr"] - p[1, "fit"]))`  

# Conclusão e Recomendações

Primeiramente, deve-se concluir que a micronumerosidade é um critério que
deveria ser menos rigoroso na normatização. A presença de poucos dados pode
fazer com que a estimação não seja tão boa, porém a retirada de dados ou omissão
de variávies relevantes pode ser ainda pior. A princípio, a norma deveria deixar
o modelo dizer se a quantidade de dados é suficiente ou não: no caso da variável
apresentar significância estatística, por que removê-la?

A opção de se retirar os dados em situação de esquina e ajustar um modelo apenas
para os dados de meio de quadra (segunda abordagem) não se mostrou uma boa
solução: no final o que se tem é um modelo apenas para lotes em meio de quadra,
sem qualquer parâmetro para se inferir o valor dos lotes de esquina. Além do 
mais, dados estão sendo jogados fora (20% deles), o que faz com que a estimação
dos coeficientes piorar.

A opção de se utilizar a primeira abordagem, omitindo-se a variável com problema
de micronumerosidade (no caso, `Situacao`) pode ser feita, mas com o devido
cuidado: o(s) valor(es) do(s) coeficiente(s) estimados para a(s) variável(eis)
efetivamente utilizada(s) (no caso apenas `Area`) deve(m) ser visto(s) com
ressalvas, pois nele(s) estão embutidos os efeitos da variável omitida. A
estimativa central calculada com este modelo encontra-se sempre um pouco abaixo
ou acima da "real". É mais ou menos como se o modelo de regressão estivesse
"errado" (todos os modelos estão errados), mas ainda fosse útil (as previsões
com ele obtidas são razoáveis). O modelo, porém, avalia lotes em meio de quadra
e lotes de esquina com os mesmos valores. Isto significa que as estimativas
estarão apenas um pouco maiores para os lotes de meio de quadra e um pouco
menores para os lotes de esquina. Mas quão maiores/menores? O intervalo de
predição, nos casos apresentados, mostrou ser um bom parâmetro, enquanto o Campo
de Arbítrio não se mostrou adequado.

Outra questão a ser revisada pela NBR 14.653-02 é a questão dos desvios em
relação às hipóteses da inferência clássica: com a omissão de variável
relevante, conforme demonstrado, o esperado é que algumas hipóteses sejam
violadas, mas isto não é impeditivo da utilização do modelo: a utilização de 
erros robustos (Eicker-White) para os intervalos de confiança e predição podem 
solucionar o problema a contento.

Com relação ao Campo de Arbítrio do Avaliador, a princípio entende-se que este
deva ser mantido na NBR 14.653-02, até por compatilidade com as outras partes da
da NBR 14.653, mas também por compatibilidade com os outros métodos não 
estatísticos, como os métodos de avaliação por fatores. 

A sua aplicação, contudo, deveria ser revista: primeiramente, entende-se que é
um erro a livre utilização de todo o intervalo do CA sem um critério que possa
dar embasamento a esta utilização. A amplitude máxima do CA deveria ser mantida,
porém como limitante superior/inferior para os intervalos de valores
admissíveis, não como uma opção de livre escolha para o avaliador adotar
qualquer valor dentro deste intervalo, como ocorre na atual normatização. Seria
boa regra permitir ao avaliador que adote valores dentro do CA, porém limitados
aos valores do Intervalo de Predição do modelo de regressão linear. Ou, de outra
forma, que seja permitido ao avaliador adotar qualquer valor dentro do IP, desde
que este esteja dentro do intervalo de mais ou menos 15% da estimativa central.

# Referências {-}
